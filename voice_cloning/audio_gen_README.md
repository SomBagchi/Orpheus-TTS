# Audio Generation Script

This script samples random items from the voice cloning validation dataset and generates multiple audio files for comparison:

## Generated Files

For each sampled voice, the script creates 4 audio files in the `samples/{episode_id}/` directory:

1. `reference.mp3` - The original reference voice from the input
2. `real_sample.mp3` - The actual sample voice from the dataset
3. `base_model.mp3` - Generated by the base Orpheus TTS model
4. `finetuned_model.mp3` - Generated by the voice cloning finetuned model

## Usage

```bash
# Make sure you have the voice cloning models trained
python voice_cloning/audio_gen.py
```

## Requirements

- PyTorch
- Transformers
- Datasets library
- SNAC decoder (from Orpheus TTS)
- ffmpeg (optional, for MP3 conversion)

## How It Works

The script:
1. Loads random samples from the validation dataset
2. Extracts speech tokens between start and end markers
3. Runs inference on both the base and finetuned models
4. Generates and saves audio files for comparison

## Output Directory Structure

```
samples/
  ├── {episode_id_1}/
  │   ├── reference.mp3
  │   ├── real_sample.mp3
  │   ├── base_model.mp3
  │   └── finetuned_model.mp3
  ├── {episode_id_2}/
  │   ├── ...
  └── ...
```

This allows for easy comparison between the original voice, the dataset sample, and the generated outputs from both models. 
